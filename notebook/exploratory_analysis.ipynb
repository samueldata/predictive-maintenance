{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance System\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Este projeto visa implementar um sistema de manutenção preditiva utilizando dados de sensores. O código está estruturado para ser executado diretamente em um ambiente Jupyter Notebook. Ao executar cada célula, o código realiza todas as etapas necessárias para a configuração, geração de dados, treinamento de modelos e geração de relatórios.\n",
    "\n",
    "## Estrutura do Projeto\n",
    "\n",
    "1. **Configuração de Caminho:** Define o caminho para armazenar dados simulados e garante que o diretório necessário esteja criado.\n",
    "2. **Geração de Dados Simulados:** Cria e adiciona novos dados simulados a um arquivo CSV.\n",
    "3. **Carregamento e Análise Exploratória de Dados:** Carrega os dados existentes e realiza uma análise inicial, visualizando estatísticas e gráficos.\n",
    "4. **Processamento de Dados:** Limpa e normaliza os dados, e realiza engenharia de características.\n",
    "5. **Desenvolvimento do Modelo:**\n",
    "   - **Divisão dos Dados:** Separa os dados em conjuntos de treinamento e teste.\n",
    "   - **Treinamento do Modelo:** Treina um modelo de RandomForestClassifier com os dados de treinamento.\n",
    "   - **Avaliação do Modelo:** Avalia o desempenho do modelo com o conjunto de teste.\n",
    "6. **Implementação com TensorFlow:** Constrói e treina uma rede neural usando TensorFlow.\n",
    "7. **Geração de Gráficos de Desempenho do Modelo:** Cria gráficos para visualização da precisão e perda durante o treinamento.\n",
    "8. **Geração de Relatório em PDF:** Compila um relatório em PDF contendo resultados do modelo e gráficos gerados.\n",
    "9. **Coleta Simulada de Dados e Envio de Alertas:** Simula a coleta contínua de dados dos sensores e envia alertas baseados nas previsões do modelo.\n",
    "\n",
    "## Como Executar\n",
    "\n",
    "Para executar o notebook:\n",
    "\n",
    "1. **Inicie o notebook Jupyter.**\n",
    "2. **Execute cada célula sequencialmente (pressionando `Shift + Enter`).** \n",
    "   - As células irão configurar o ambiente, gerar e processar dados, treinar e avaliar modelos, e finalmente gerar gráficos e relatórios.\n",
    "\n",
    "Todas as etapas são autossuficientes e o código está preparado para ser executado diretamente. Certifique-se de que todas as bibliotecas necessárias estão instaladas e o ambiente está configurado corretamente.\n",
    "\n",
    "## Requisitos\n",
    "\n",
    "Certifique-se de que as seguintes bibliotecas estão instaladas:\n",
    "\n",
    "- `numpy`\n",
    "- `pandas`\n",
    "- `scikit-learn`\n",
    "- `tensorflow`\n",
    "- `requests`\n",
    "- `fpdf`\n",
    "- `matplotlib`\n",
    "\n",
    "Você pode instalar as bibliotecas necessárias com o comando:\n",
    "```bash\n",
    "pip install numpy pandas scikit-learn tensorflow requests fpdf matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração de caminho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Definindo o caminho relativo ao diretório de dados\n",
    "base_dir = os.path.join(os.getcwd(), '..', 'data')\n",
    "\n",
    "# Verificando se o diretório existe; se não, cria\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "# Definindo o caminho completo para o arquivo CSV\n",
    "file_path = os.path.join(base_dir, 'sensor_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gerando dados simulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Definindo parâmetros para os novos dados\n",
    "np.random.seed(45)\n",
    "num_samples = 1000\n",
    "\n",
    "# Função para carregar dados existentes e adicionar novos dados\n",
    "def append_to_csv(file_path, new_data):\n",
    "    if os.path.exists(file_path):\n",
    "        existing_df = pd.read_csv(file_path)\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "        updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "    else:\n",
    "        updated_df = pd.DataFrame(new_data)\n",
    "\n",
    "    updated_df.to_csv(file_path, index=False)\n",
    "    print(f\"Dados atualizados salvos em: {file_path}\")\n",
    "\n",
    "# Gerar novos dados simulados\n",
    "temperature = np.random.normal(loc=70, scale=5, size=num_samples)\n",
    "vibration = np.random.normal(loc=30, scale=2, size=num_samples)\n",
    "pressure = np.random.normal(loc=100, scale=10, size=num_samples)\n",
    "failure = np.random.choice([0, 1], size=num_samples, p=[0.95, 0.05])\n",
    "\n",
    "# Criar o DataFrame com os novos dados\n",
    "new_data = {\n",
    "    'temperature': temperature,\n",
    "    'vibration': vibration,\n",
    "    'pressure': pressure,\n",
    "    'failure': failure\n",
    "}\n",
    "\n",
    "# Adicionar os novos dados ao CSV existente\n",
    "append_to_csv(file_path, new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carregamento e Análise Exploratória de Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(df.head())\n",
    "    print(df.describe())\n",
    "    df.plot(subplots=True, figsize=(10, 12))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Arquivo não encontrado no caminho: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Processamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Removendo valores ausentes\n",
    "df = df.dropna()\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Feature Engineering\n",
    "df_scaled['temperature_vibration_ratio'] = df_scaled['temperature'] / df_scaled['vibration']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Desenvolvimento do Modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dos Dados:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_scaled.drop('failure', axis=1)  # Features\n",
    "y = df_scaled['failure']  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação e o tratamento de dados após a divisão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = df[['temperature', 'vibration', 'pressure']]\n",
    "y = df['failure']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.isnull().sum())\n",
    "print(np.isinf(X_train).sum())\n",
    "\n",
    "X_train = X_train.fillna(X_train.mean())\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "print(y_train.isnull().sum())\n",
    "print(np.isinf(y_train).sum())\n",
    "\n",
    "y_train = y_train.fillna(y_train.mean())\n",
    "y_train = y_train.replace([np.inf, -np.inf], np.nan).dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do Modelo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implementação com TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Geração de Gráficos de Desempenho do modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def criar_graficos(history):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(base_dir, 'accuracy_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(base_dir, 'loss_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "criar_graficos(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Gerando o Relatório em PDF do modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "import os\n",
    "\n",
    "def gerar_relatorio(accuracy, loss):\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    pdf.cell(200, 10, txt=\"Relatório de Resultados do Modelo\", ln=True, align='C')\n",
    "\n",
    "    pdf.ln(10)\n",
    "    pdf.cell(200, 10, txt=f\"Precisão no Teste: {accuracy*100:.2f}%\", ln=True)\n",
    "    pdf.cell(200, 10, txt=f\"Perda no Teste: {loss:.4f}\", ln=True)\n",
    "\n",
    "    pdf.ln(10)\n",
    "    pdf.cell(200, 10, txt=\"Gráficos de Treinamento\", ln=True)\n",
    "    \n",
    "    pdf.image(os.path.join(base_dir, 'accuracy_plot.png'), x=10, y=60, w=180)\n",
    "    pdf.add_page()\n",
    "    pdf.image(os.path.join(base_dir, 'loss_plot.png'), x=10, y=10, w=180)\n",
    "\n",
    "    pdf.output(os.path.join(base_dir, \"relatorio_resultados.pdf\"))\n",
    "    print(\"Relatório PDF gerado com sucesso.\")\n",
    "\n",
    "gerar_relatorio(accuracy, loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Coleta Simulada de Dados e Envio de Alertas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def initialize_csv(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        df = pd.DataFrame(columns=['temperature', 'vibration', 'pressure', 'failure'])\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "initialize_csv(file_path)\n",
    "\n",
    "def send_alert(message):\n",
    "    url = \"https://api.smsgateway/send\"  # URL da API do serviço de alerta\n",
    "    data = {\n",
    "        \"message\": message,\n",
    "        \"to\": \"numero_do_telefone\"\n",
    "    }\n",
    "    response = requests.post(url, data=data)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Alerta enviado com sucesso!\")\n",
    "    else:\n",
    "        print(\"Falha ao enviar alerta.\")\n",
    "\n",
    "def process_new_data(sensor_data):\n",
    "    processed_data = np.array(sensor_data[:-1]).reshape(1, -1)\n",
    "    prediction = model.predict(processed_data)\n",
    "    print(f\"Actual prediction: {prediction}\")\n",
    "\n",
    "    if prediction > 0.5:\n",
    "        print(\"Alerta: Possível falha detectada. Verifique a máquina.\")\n",
    "        # send_alert(\"Alerta: Possível falha detectada. Verifique a máquina.\")\n",
    "    else:\n",
    "        print(\"Nenhuma falha detectada.\")\n",
    "\n",
    "    return sensor_data\n",
    "\n",
    "def simulate_sensor_data():\n",
    "    while True:\n",
    "        temperature = np.random.normal(loc=70, scale=5)\n",
    "        vibration = np.random.normal(loc=30, scale=2)\n",
    "        pressure = np.random.normal(loc=100, scale=10)\n",
    "        failure = np.random.choice([0, 1], size=1, p=[0.95, 0.05])[0]\n",
    "\n",
    "        sensor_data = [temperature, vibration, pressure, failure]\n",
    "        processed_data = process_new_data(sensor_data)\n",
    "        df = pd.DataFrame([processed_data], columns=['temperature', 'vibration', 'pressure', 'failure'])\n",
    "        append_to_csv(file_path, df.to_dict(orient='records'))\n",
    "        \n",
    "        time.sleep(10)  # Intervalo de coleta de dados (10 segundos)\n",
    "\n",
    "simulate_sensor_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
